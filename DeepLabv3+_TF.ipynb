{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLabv3+_TF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOQ1w5UJ4/Cm4JLgj4Y2Kam",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yuji-github/DeepLabV3-TensorFlow/blob/main/DeepLabv3%2B_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiu6iSWgsW6R",
        "outputId": "882d5f55-fdbb-4d98-e19d-6b66537a7611"
      },
      "source": [
        "import glob, os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Concatenate, UpSampling2D, AveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.data import Dataset, AUTOTUNE\n",
        "from keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/DeepLab/"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/DeepLab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83LEPg_pySPc"
      },
      "source": [
        "For Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv1AQzaqStHD"
      },
      "source": [
        "def read_image(path): \n",
        "  path = path.decode()  # without this, name is encoded like 'b'\n",
        "  image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "  image = image / 255.0 # normalization \n",
        "  image = cv2.resize(image, (128, 128)) # resize to 128x128   \n",
        "  image = image.astype(np.float32) # (128, 128, 3)\n",
        "\n",
        "  return image"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-PnvrOzTNZN"
      },
      "source": [
        "def read_mask(path): \n",
        "  path = path.decode()  # without this, name is encoded like 'b'\n",
        "  mask = cv2.imread(path, cv2.IMREAD_GRAYSCALE) # (128, 128)\n",
        "  mask = mask / 255.0 # normalization \n",
        "  mask = cv2.resize(mask, (128, 128)) # resize to 128x128  \n",
        "  mask = mask.astype(np.float32)\n",
        "  mask = np.expand_dims(mask, axis= -1) # (128, 128, 1)  \n",
        "  \n",
        "  return mask"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8Nef8LqVA7k"
      },
      "source": [
        "def preprocess(image, mask): # map calls this function\n",
        "\n",
        "  def f(image, mask): # preprocess calls this function\n",
        "    \n",
        "    image = read_image(image) # params -> /content/drive/MyDrive/DeepLab/images/***.png \n",
        "    mask = read_mask(mask)\n",
        "    \n",
        "    return image, mask\n",
        "\n",
        "  images, masks = tf.numpy_function(f, [image, mask], [tf.float32, tf.float32])\n",
        "  images.set_shape([128, 128, 3]) # must match the first layer in deeplab\n",
        "  masks.set_shape([128, 128, 1]) # must match the last layer in deeplab\n",
        "\n",
        "  return  images, masks"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2tJ1rhTUpm-"
      },
      "source": [
        "def tf_dataset(image, mask, batch=2): # default batch is 8\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((image, mask))\n",
        "  dataset = dataset.map(preprocess) # map needs function\n",
        "  dataset = dataset.batch(batch)\n",
        "  dataset = dataset.prefetch(10)\n",
        "\n",
        "  return dataset"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74NRehM-xnu0"
      },
      "source": [
        "def data_load():\n",
        "  IMAGE_DIR = 'train_images'\n",
        "  MASK_DIR = 'train_masks'\n",
        "\n",
        "  imageList = []\n",
        "  maskList = []\n",
        "\n",
        "  for dirname, _, filenames in os.walk(IMAGE_DIR):\n",
        "      for filename in filenames:\n",
        "            imageList.append(os.path.join(dirname, filename))\n",
        "\n",
        "  for dirname, _, filenames in os.walk(MASK_DIR):\n",
        "      for filename in filenames:\n",
        "            maskList.append(os.path.join(dirname, filename))\n",
        "\n",
        "  imageList.sort() \n",
        "  maskList.sort()\n",
        "\n",
        "  dataset = tf_dataset(imageList, maskList, 8) # retunr is (16, 128, 128, 3) (16, 128, 128, 1)\n",
        "\n",
        "  return dataset"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDno9t4ldhXY"
      },
      "source": [
        "def val_data_load(): # val dataset has 16 images\n",
        "  IMAGE_DIR = 'val_images'\n",
        "  MASK_DIR = 'val_masks'\n",
        "\n",
        "  val_imageList = []\n",
        "  val_maskList = []\n",
        "\n",
        "  for dirname, _, filenames in os.walk(IMAGE_DIR):\n",
        "      for filename in filenames:\n",
        "            val_imageList.append(os.path.join(dirname, filename))\n",
        "\n",
        "  for dirname, _, filenames in os.walk(MASK_DIR):\n",
        "      for filename in filenames:\n",
        "            val_maskList.append(os.path.join(dirname, filename))\n",
        "\n",
        "  val_imageList.sort() \n",
        "  val_maskList.sort()\n",
        "\n",
        "  val_dataset = tf_dataset(val_imageList, val_maskList, 8) # retunr is (8, 128, 128, 3) (8, 128, 128, 1)\n",
        "\n",
        "  return val_dataset"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jq8svsGzyOoN"
      },
      "source": [
        "DeepLabV3+"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRMF4s8ZM7M5"
      },
      "source": [
        "def backbone(input_shape): \n",
        "  i= Input(input_shape)\n",
        "\n",
        "  backbone = ResNet50(include_top=False, input_tensor=i) # when you have a tensor that you want to be the input.\n",
        "  \n",
        "  return (i, backbone.get_layer('conv4_block6_out').output, backbone.get_layer('conv2_block3_out').output)  # the last Resnet for encoding, other's for decoding layers are going back "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBfHSj2hVVWu"
      },
      "source": [
        "def ASPP(input_shape): \n",
        "\n",
        "  pool_size = (input_shape.shape[1], input_shape.shape[2]) # assume (8, 8)\n",
        "  # ASPP Part\n",
        "\n",
        "  # --- Image Pooling ----\n",
        "  image_pool = AveragePooling2D(pool_size)(input_shape) # after this layer: (None, 1, 1, 2048)\n",
        "  image_pool = Conv2D(128, (1,1), padding='same', use_bias=False)(image_pool)\n",
        "  image_pool = BatchNormalization()(image_pool)\n",
        "  iamge_pool = Activation('relu')(image_pool) # after this layer: (None, 1, 1, 128)\n",
        "  image_pool = UpSampling2D(pool_size, interpolation='bilinear')(iamge_pool) # after this layer: (None, 8, 8, 128)\n",
        "\n",
        "  # --- 1x1 Conv ----\n",
        "  one = Conv2D(128, (1,1), padding='same', use_bias=False)(input_shape)\n",
        "  one = BatchNormalization()(one)\n",
        "  one = Activation('relu')(one) # after this layer: (None, 8, 8, 128)\n",
        "\n",
        "  # --- 3x3 Conv Rate 6 ----\n",
        "  rate_6 = Conv2D(128, (3,3), padding='same', use_bias=False, dilation_rate=6)(input_shape) # dilation_rate = 6 is key step \n",
        "  rate_6 = BatchNormalization()(rate_6)\n",
        "  rate_6 = Activation('relu')(rate_6) # after this layer: (None, 8, 8, 128)\n",
        "\n",
        "  # --- 3x3 Conv Rate 12 ----\n",
        "  rate_12 = Conv2D(128, (3,3), padding='same', use_bias=False, dilation_rate=12)(input_shape) # dilation_rate = 12 is key step \n",
        "  rate_12 = BatchNormalization()(rate_12)\n",
        "  rate_12 = Activation('relu')(rate_12) # after this layer: (None, 8, 8, 128)\n",
        "\n",
        "  # --- 3x3 Conv Rate 18 ----\n",
        "  rate_18 = Conv2D(128, (3,3), padding='same', use_bias=False, dilation_rate=18)(input_shape) # dilation_rate = 18 is key step \n",
        "  rate_18 = BatchNormalization()(rate_18)\n",
        "  rate_18 = Activation('relu')(rate_18) # after this layer: (None, 8, 8, 128)\n",
        "\n",
        "\n",
        "  # After ASPP Part  \n",
        "  # --- Concatenate ---- *Make Sure all sizes are the same before Concatenation\n",
        "  aspp = Concatenate()([image_pool, one, rate_6, rate_12, rate_18]) # after this layer: (None, 8, 8, 640) 640 from 128 feature each * 5\n",
        "  \n",
        "  # --- 1x1 Conv for UpSamling ----\n",
        "  for_up = Conv2D(128, (1,1), padding='same', use_bias=False)(aspp)\n",
        "  for_up = BatchNormalization()(for_up)\n",
        "  for_up = Activation('relu')(for_up) # after this layer: (None, 8, 8, 128)\n",
        "\n",
        "  return for_up"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nadZRNj5jOV"
      },
      "source": [
        "def decoding(input_shape):  \n",
        "  decode_one = Conv2D(32, (1,1), padding='same', use_bias=False)(input_shape) # *output features are arbitrary\n",
        "  decode_one = BatchNormalization()(decode_one)\n",
        "  decode_one = Activation('relu')(decode_one) # after this layer: (None, 32, 32, 64)\n",
        "\n",
        "  return decode_one"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s74ObM0_98t3"
      },
      "source": [
        "def deeplabv3(input_shape):\n",
        "  # step1: get input shape of images\n",
        "  i = input_shape # suppose layer shape is (128, 128, 3)\n",
        "\n",
        "  # --- Encoding Section ----\n",
        "\n",
        "  # step2: through backbone (Resnet50)\n",
        "  # we can replace this backbone ResNeSt in the future \n",
        "  i, encode_layer, decode_layer = backbone(i) # retun shapes: encode (None, 8, 8, 1024), decode (None, 32, 32, 256)\n",
        "\n",
        "  # step3: pass the encode_layer to ASPP \n",
        "  end_encoding_layer = ASPP(encode_layer)  \n",
        "   \n",
        "  # step3-2: UpSamling for Concatenation \n",
        "  end_encoding_layer = UpSampling2D((4, 4), interpolation='bilinear')(end_encoding_layer) # after this layer: (None, 32, 32, 128) \n",
        "\n",
        "\n",
        "  # --- Decoding Section ---- need to get the same shape from ResNet (None, 32, 32, 256)\n",
        "\n",
        "  # step4: Decoding and Concatenating  \n",
        "  decode_one = decoding(decode_layer) \n",
        "\n",
        "  # step5: Concatenation \n",
        "  mix_layer = Concatenate()([end_encoding_layer, decode_one]) # after this layer: (None, 32, 32, 320)\n",
        "\n",
        "\n",
        "  # --- Prepare Output Section ---- \n",
        "  # step6: 3x3 Conv (at least 1 block needs *output features are arbitrary)\n",
        "  three = Conv2D(128, (3,3), padding='same', use_bias=False)(mix_layer) # for 256 Conv2D(256, (3,3),\n",
        "  three = BatchNormalization()(three)\n",
        "  three = Activation('relu')(three)\n",
        "\n",
        "  three = Conv2D(128, (3,3), padding='same', use_bias=False)(three) # for 256 Conv2D(512, (3,3),\n",
        "  three = BatchNormalization()(three)\n",
        "  three = Activation('relu')(three) # after this layer (None, 32, 32, 512)\n",
        "\n",
        "  # step7: end of Deeplabv3 make sure out put size is the same as input size\n",
        "  end_layer = UpSampling2D((4, 4), interpolation='bilinear')(three) # after this layer (None, 128, 128, 512)\n",
        "\n",
        "  # --- Output Section ---- \n",
        "  output = Conv2D(1, (1,1))(end_layer)\n",
        "  output = Activation('sigmoid')(output) # (None, 128, 128, 1)\n",
        "  \n",
        "  # model summary and compile\n",
        "  return Model(i, output)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H77dKAGx-59M"
      },
      "source": [
        "Loss Function for Semantic Segmentation\n",
        "https://www.youtube.com/watch?v=AZr64OxshLo&t=785s More Info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go8ggLzLCQ0I"
      },
      "source": [
        "def iou(y_true, y_pred):\n",
        "    def f(y_true, y_pred):\n",
        "        intersection = (y_true * y_pred).sum()\n",
        "        union = y_true.sum() + y_pred.sum() - intersection\n",
        "        x = (intersection + 1e-15) / (union + 1e-15)\n",
        "        x = x.astype(np.float32)\n",
        "        return x\n",
        "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWV-IzIFCRvm"
      },
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    smooth = 1e-15\n",
        "    y_true = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waL3JoFufhF6"
      },
      "source": [
        "def dice_loss(y_true, y_pred): \n",
        "  # must be 1 - dice_coef for backpropagation\n",
        "  return 1 - dice_coef(y_true, y_pred) # 1- numerator/denominator"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-o-Eh0s-1Oa"
      },
      "source": [
        "Call Back"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGmO4RtYkm6l"
      },
      "source": [
        "def lr_decay(epoch):\n",
        "    initial_learningrate=2e-3\n",
        "    if epoch < 2:\n",
        "        return initial_learningrate\n",
        "    else:\n",
        "        return initial_learningrate * 0.99 ** epoch"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJFaJVxOCoCk"
      },
      "source": [
        "Prediction (Vizulaization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5yEhxOneA0E"
      },
      "source": [
        "def eval(deeplab):\n",
        "  IMAGE_DIR = '/content/drive/MyDrive/DeepLab/test_images/'\n",
        "  imageList = []\n",
        "\n",
        "  for dirname, _, filenames in os.walk(IMAGE_DIR):\n",
        "      for filename in filenames:\n",
        "            imageList.append(os.path.join(dirname, filename))\n",
        " \n",
        "  imageList.sort() \n",
        "  test_image = random.choice(imageList)\n",
        "  test_mask = test_image.replace('test_images', 'test_masks')\n",
        "\n",
        "  \"\"\" Getting an image \"\"\"\n",
        "  image = cv2.imread(test_image, cv2.IMREAD_COLOR) # RGB -> (512, 384, 3)\n",
        "  h, w, _ = image.shape # to back to the original size (predict_mask)\n",
        "  x = cv2.resize(image, (128, 128))\n",
        "  x = x/255.0 # normalization values are 0-1\n",
        "  x = x.astype(np.float32)\n",
        "  x = np.expand_dims(x, axis=0) # (1, 128, 128, 3)\n",
        "\n",
        "  \"\"\" Prediction the mask \"\"\"\n",
        "  y = deeplab.predict(x)[0] # (128, 128, 1) [0]-> drop off the first dim, this case 1\n",
        "  y = cv2.resize(y, (w, h)) # (384, 512)\n",
        "  y = np.expand_dims(y, axis=-1) # (384, 512, 1) to plot the image\n",
        "  masked_image = image * y # must do this part to get back the values becasue x/255 -> pred_y/255  \n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.imshow(masked_image)\n",
        "\n",
        "  t = test_mask\n",
        "  t_image = cv2.imread(t)\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.imshow(t_image)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyju_axfPK2O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1e24bcc4-763b-4175-8805-835fc6af912a"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        " # -- Data Loading Section ---  \n",
        " dataset = data_load() # get 128x128 images (numpy, values[pixels] are between 0-1)\n",
        " val_data = val_data_load()\n",
        "\n",
        " # -- Building Model Section --- \n",
        " i = (128, 128, 3) \n",
        " deeplab = deeplabv3(i)\n",
        "\n",
        " # --- Compile Section ---- binary_entrophy is okay as masks are black and white, but not suitable \n",
        " deeplab.compile(optimizer=Adam(), loss=dice_loss, metrics=[dice_coef, iou])\n",
        " opt = Adam()  # for speed up\n",
        " loss_fn = dice_loss # for speed up\n",
        " # print(deeplab.summary()) # check neural networks  \n",
        "\n",
        " # --- Training Section ---\n",
        " model_callback = [\n",
        "        LearningRateScheduler(lr_decay, verbose=1),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
        "        ]\n",
        "\n",
        " deeplab.fit(dataset,\n",
        "            validation_data=val_data,\n",
        "            epochs=20, \n",
        "            callbacks=model_callback)\n",
        " \n",
        " deeplab.save('/content/drive/MyDrive/DeepLab/output/model.h5') \n",
        "\n",
        " # --- Evaluation Section ---\n",
        " eval(deeplab)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.002.\n",
            "Epoch 1/20\n",
            "145/145 [==============================] - 32s 184ms/step - loss: 0.2771 - dice_coef: 0.7229 - iou: 0.5837 - val_loss: 1.0000 - val_dice_coef: 2.7837e-05 - val_iou: 1.3919e-05 - lr: 0.0020\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.002.\n",
            "Epoch 2/20\n",
            "145/145 [==============================] - 23s 160ms/step - loss: 0.1625 - dice_coef: 0.8375 - iou: 0.7218 - val_loss: 1.0000 - val_dice_coef: 2.1253e-05 - val_iou: 1.0626e-05 - lr: 0.0020\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0019602.\n",
            "Epoch 3/20\n",
            "145/145 [==============================] - 24s 162ms/step - loss: 0.1308 - dice_coef: 0.8692 - iou: 0.7693 - val_loss: 0.9999 - val_dice_coef: 6.0474e-05 - val_iou: 3.0238e-05 - lr: 0.0020\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0019405980000000002.\n",
            "Epoch 4/20\n",
            "145/145 [==============================] - 24s 162ms/step - loss: 0.1135 - dice_coef: 0.8865 - iou: 0.7968 - val_loss: 1.0000 - val_dice_coef: 1.7168e-06 - val_iou: 8.5841e-07 - lr: 0.0019\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0019211920199999999.\n",
            "Epoch 5/20\n",
            "145/145 [==============================] - 23s 162ms/step - loss: 0.1045 - dice_coef: 0.8955 - iou: 0.8113 - val_loss: 1.0000 - val_dice_coef: 4.2829e-06 - val_iou: 2.1415e-06 - lr: 0.0019\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0019019800997999998.\n",
            "Epoch 6/20\n",
            "145/145 [==============================] - 25s 169ms/step - loss: 0.0997 - dice_coef: 0.9003 - iou: 0.8191 - val_loss: 0.5990 - val_dice_coef: 0.4010 - val_iou: 0.2515 - lr: 0.0019\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.001882960298802.\n",
            "Epoch 7/20\n",
            "145/145 [==============================] - 24s 162ms/step - loss: 0.0950 - dice_coef: 0.9050 - iou: 0.8270 - val_loss: 0.5920 - val_dice_coef: 0.4080 - val_iou: 0.2564 - lr: 0.0019\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0018641306958139799.\n",
            "Epoch 8/20\n",
            "145/145 [==============================] - 24s 162ms/step - loss: 0.0923 - dice_coef: 0.9077 - iou: 0.8315 - val_loss: 0.1007 - val_dice_coef: 0.8993 - val_iou: 0.8172 - lr: 0.0019\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0018454893888558402.\n",
            "Epoch 9/20\n",
            "145/145 [==============================] - 24s 162ms/step - loss: 0.0907 - dice_coef: 0.9093 - iou: 0.8343 - val_loss: 0.2225 - val_dice_coef: 0.7775 - val_iou: 0.6364 - lr: 0.0018\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.0018270344949672817.\n",
            "Epoch 10/20\n",
            "145/145 [==============================] - 23s 160ms/step - loss: 0.0881 - dice_coef: 0.9119 - iou: 0.8385 - val_loss: 0.1169 - val_dice_coef: 0.8831 - val_iou: 0.7907 - lr: 0.0018\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.0018087641500176088.\n",
            "Epoch 11/20\n",
            "145/145 [==============================] - 24s 162ms/step - loss: 0.0871 - dice_coef: 0.9129 - iou: 0.8402 - val_loss: 0.0977 - val_dice_coef: 0.9023 - val_iou: 0.8221 - lr: 0.0018\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.0017906765085174327.\n",
            "Epoch 12/20\n",
            "145/145 [==============================] - 23s 162ms/step - loss: 0.0861 - dice_coef: 0.9139 - iou: 0.8419 - val_loss: 0.1036 - val_dice_coef: 0.8964 - val_iou: 0.8124 - lr: 0.0018\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.0017727697434322585.\n",
            "Epoch 13/20\n",
            "145/145 [==============================] - 23s 160ms/step - loss: 0.0830 - dice_coef: 0.9170 - iou: 0.8471 - val_loss: 0.0959 - val_dice_coef: 0.9041 - val_iou: 0.8250 - lr: 0.0018\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.0017550420459979358.\n",
            "Epoch 14/20\n",
            "145/145 [==============================] - 24s 164ms/step - loss: 0.0803 - dice_coef: 0.9197 - iou: 0.8517 - val_loss: 0.0895 - val_dice_coef: 0.9105 - val_iou: 0.8359 - lr: 0.0018\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.0017374916255379566.\n",
            "Epoch 15/20\n",
            "145/145 [==============================] - 24s 165ms/step - loss: 0.0790 - dice_coef: 0.9210 - iou: 0.8539 - val_loss: 0.1210 - val_dice_coef: 0.8790 - val_iou: 0.7843 - lr: 0.0017\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.001720116709282577.\n",
            "Epoch 16/20\n",
            "145/145 [==============================] - 24s 165ms/step - loss: 0.0770 - dice_coef: 0.9230 - iou: 0.8574 - val_loss: 0.0847 - val_dice_coef: 0.9153 - val_iou: 0.8441 - lr: 0.0017\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.0017029155421897512.\n",
            "Epoch 17/20\n",
            "145/145 [==============================] - 25s 171ms/step - loss: 0.0750 - dice_coef: 0.9250 - iou: 0.8608 - val_loss: 0.0821 - val_dice_coef: 0.9179 - val_iou: 0.8486 - lr: 0.0017\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.0016858863867678536.\n",
            "Epoch 18/20\n",
            "145/145 [==============================] - 24s 163ms/step - loss: 0.0748 - dice_coef: 0.9252 - iou: 0.8612 - val_loss: 0.1652 - val_dice_coef: 0.8348 - val_iou: 0.7166 - lr: 0.0017\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.001669027522900175.\n",
            "Epoch 19/20\n",
            "145/145 [==============================] - 24s 162ms/step - loss: 0.0738 - dice_coef: 0.9262 - iou: 0.8629 - val_loss: 0.0888 - val_dice_coef: 0.9112 - val_iou: 0.8370 - lr: 0.0017\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.0016523372476711733.\n",
            "Epoch 20/20\n",
            "145/145 [==============================] - 24s 163ms/step - loss: 0.0730 - dice_coef: 0.9270 - iou: 0.8643 - val_loss: 0.1173 - val_dice_coef: 0.8827 - val_iou: 0.7906 - lr: 0.0017\n",
            "WARNING:tensorflow:6 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f38a667d680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f38a667d680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}